{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1a8aa2",
   "metadata": {},
   "source": [
    "# Defining Schema Explicitly in PySpark with Delta Lake\n",
    "\n",
    "This notebook demonstrates how to define a schema explicitly using `StructType` and `StructField` in PySpark when working with Delta Lake tables.\n",
    "\n",
    "Explicit schema definition is useful for:\n",
    "- Ensuring data consistency\n",
    "- Avoiding schema inference errors\n",
    "- Improving performance during data loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce90b9b1",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup PySpark Session\n",
    "\n",
    "We begin by initializing a Spark session with Delta Lake support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExplicitSchemaExample\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7252f",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Defining Schema Using `StructType` and `StructField`\n",
    "\n",
    "We define a schema explicitly using PySpark's `StructType` and `StructField` classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4fe3f",
   "metadata": {},
   "source": [
    "## ðŸ§ª Creating DataFrame with Explicit Schema\n",
    "\n",
    "We create a DataFrame using the defined schema and a list of tuples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"Alice\", 30), (2, \"Bob\", 25), (3, \"Charlie\", 35)]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee7610",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Saving DataFrame as Delta Table\n",
    "\n",
    "We save the DataFrame as a Delta table using the `.write.format(\"delta\")` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/explicit_schema_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b50601",
   "metadata": {},
   "source": [
    "## ðŸ“– Reading Delta Table with Explicit Schema\n",
    "\n",
    "We can read the Delta table back and verify the schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b098a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark.read.format(\"delta\").load(\"/tmp/delta/explicit_schema_table\")\n",
    "df_read.printSchema()\n",
    "df_read.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c047fa",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "- We defined a schema explicitly using `StructType` and `StructField`.\n",
    "- Created a DataFrame with the schema.\n",
    "- Saved and read the data using Delta Lake format.\n",
    "\n",
    "Explicit schema definition is a best practice for robust and scalable data pipelines.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
