{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed43ec5",
   "metadata": {},
   "source": [
    "# Managed vs. External Delta Lake Tables\n",
    "\n",
    "This notebook demonstrates the difference between **Managed** and **External** Delta Lake tables using **PySpark**.\n",
    "\n",
    "Delta Lake brings ACID transactions to Apache Spark and big data workloads. Understanding the distinction between managed and external tables is crucial for data management and governance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f41ac6",
   "metadata": {},
   "source": [
    "## üîç Definitions\n",
    "\n",
    "### Managed Table\n",
    "- Spark manages both the **metadata** and the **data**.\n",
    "- Dropping the table deletes both the metadata and the data files.\n",
    "\n",
    "### External Table\n",
    "- Spark manages only the **metadata**.\n",
    "- The data resides at an external location.\n",
    "- Dropping the table deletes only the metadata, not the data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e673529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaTableExample\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14825c24",
   "metadata": {},
   "source": [
    "## üìò Example 1: Creating a Managed Delta Table\n",
    "\n",
    "We create a managed Delta table by writing a DataFrame and saving it as a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"Alice\", 30), (2, \"Bob\", 25)]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Save as a managed table\n",
    "df.write.format(\"delta\").saveAsTable(\"managed_people\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the managed table\n",
    "spark.sql(\"SELECT * FROM managed_people\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the managed table (this deletes both metadata and data)\n",
    "spark.sql(\"DROP TABLE managed_people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f118ad",
   "metadata": {},
   "source": [
    "## üìò Example 2: Creating an External Delta Table\n",
    "\n",
    "We create an external Delta table by writing data to a specific path and registering it as a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_path = \"/tmp/external_people\"\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(external_path)\n",
    "\n",
    "# Register the external table\n",
    "spark.sql(f\"CREATE TABLE external_people USING DELTA LOCATION '{external_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the external table\n",
    "spark.sql(\"SELECT * FROM external_people\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the external table (this deletes only the metadata)\n",
    "spark.sql(\"DROP TABLE external_people\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee989af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data directly from the path to verify it still exists\n",
    "spark.read.format(\"delta\").load(external_path).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b608e",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "| Feature | Managed Table | External Table |\n",
    "|--------|----------------|----------------|\n",
    "| Metadata Managed By | Spark | Spark |\n",
    "| Data Managed By | Spark | User |\n",
    "| Drop Table Deletes Data | ‚úÖ Yes | ‚ùå No |\n",
    "| Use Case | Temporary or internal datasets | Shared or persistent datasets |\n",
    "\n",
    "Understanding the distinction helps in choosing the right table type for your data architecture.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
