{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8862c34c",
   "metadata": {},
   "source": [
    "# Enabling Schema Evolution in Delta Lake using PySpark\n",
    "\n",
    "This notebook demonstrates how to enable **schema evolution** in Delta Lake using PySpark. Schema evolution allows you to append data with new columns to an existing Delta table by using the `mergeSchema` option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd33f32",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaSchemaEvolution\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eda131",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Create Initial Delta Table\n",
    "We start by creating a simple DataFrame and saving it as a Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define schema\n",
    "schema_v1 = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "data_v1 = [(1, \"Alice\"), (2, \"Bob\")]\n",
    "df_v1 = spark.createDataFrame(data_v1, schema=schema_v1)\n",
    "\n",
    "# Save as Delta table\n",
    "df_v1.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/schema_evolution_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101771f3",
   "metadata": {},
   "source": [
    "## âž• Append Data with New Column\n",
    "Now we create a new DataFrame with an additional column `age` and append it to the existing Delta table using `mergeSchema=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new schema with an additional column\n",
    "schema_v2 = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create new DataFrame\n",
    "data_v2 = [(3, \"Charlie\", 30), (4, \"Diana\", 28)]\n",
    "df_v2 = spark.createDataFrame(data_v2, schema=schema_v2)\n",
    "\n",
    "# Append with schema evolution\n",
    "df_v2.write.format(\"delta\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"/tmp/delta/schema_evolution_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1659d6",
   "metadata": {},
   "source": [
    "## ðŸ“„ Read and Display Final Table\n",
    "We read the Delta table to verify that the schema has evolved to include the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = spark.read.format(\"delta\").load(\"/tmp/delta/schema_evolution_demo\")\n",
    "df_final.printSchema()\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871fc95",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- Schema evolution allows appending data with new columns.\n",
    "- Use `.option(\"mergeSchema\", \"true\")` when writing to Delta tables.\n",
    "- This feature is useful for evolving data models without rewriting existing data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
