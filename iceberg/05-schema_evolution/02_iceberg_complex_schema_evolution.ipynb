{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7636173a",
   "metadata": {},
   "source": [
    "# üßä Apache Iceberg - Complex Schema Evolution Scenario\n",
    "This notebook demonstrates a more advanced schema evolution journey in Apache Iceberg using PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f2377",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è SparkSession Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340c3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergComplexSchemaEvolution\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"/home/jovyan/iceberg/warehouse\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8449e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS local.db.orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c609d",
   "metadata": {},
   "source": [
    "## üìò Step 1: Create Initial Orders Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e939eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE local.db.orders (\n",
    "        order_id INT,\n",
    "        customer_id INT,\n",
    "        order_date STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea1cc2",
   "metadata": {},
   "source": [
    "## ‚ûï Step 2: Add Columns for Order Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60efc735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"ALTER TABLE local.db.orders ADD COLUMN amount DOUBLE\")\n",
    "spark.sql(\"ALTER TABLE local.db.orders ADD COLUMN currency STRING\")\n",
    "spark.sql(\"ALTER TABLE local.db.orders ADD COLUMN is_priority BOOLEAN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6104911",
   "metadata": {},
   "source": [
    "## üîÑ Step 3: Rename and Reorder Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c650ee65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"ALTER TABLE local.db.orders RENAME COLUMN order_date TO placed_at\")\n",
    "spark.sql(\"ALTER TABLE local.db.orders ALTER COLUMN is_priority AFTER order_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6116d",
   "metadata": {},
   "source": [
    "## üìù Step 4: Insert Data After Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e89a68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO local.db.orders VALUES\n",
    "    (1, true, 101, '2024-12-01', 150.0, 'USD'),\n",
    "    (2, false, 102, '2024-12-02', 75.5, 'EUR')\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7babc",
   "metadata": {},
   "source": [
    "## üîß Step 5: Change Type, Drop Unused Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3998ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"ALTER TABLE local.db.orders ALTER COLUMN customer_id TYPE BIGINT\")\n",
    "spark.sql(\"ALTER TABLE local.db.orders DROP COLUMN currency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3ce01",
   "metadata": {},
   "source": [
    "## üß± Step 6: Add Nested Struct Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487daf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    ALTER TABLE local.db.orders ADD COLUMN shipping_info STRUCT<city:STRING, country:STRING>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecdde3",
   "metadata": {},
   "source": [
    "## üìä Step 7: Final Schema and Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f41bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------+-------+\n",
      "|col_name     |data_type                         |comment|\n",
      "+-------------+----------------------------------+-------+\n",
      "|order_id     |int                               |NULL   |\n",
      "|is_priority  |boolean                           |NULL   |\n",
      "|customer_id  |bigint                            |NULL   |\n",
      "|placed_at    |string                            |NULL   |\n",
      "|amount       |double                            |NULL   |\n",
      "|shipping_info|struct<city:string,country:string>|NULL   |\n",
      "+-------------+----------------------------------+-------+\n",
      "\n",
      "+--------+-----------+-----------+----------+------+-------------+\n",
      "|order_id|is_priority|customer_id| placed_at|amount|shipping_info|\n",
      "+--------+-----------+-----------+----------+------+-------------+\n",
      "|       1|       true|        101|2024-12-01| 150.0|         NULL|\n",
      "|       2|      false|        102|2024-12-02|  75.5|         NULL|\n",
      "+--------+-----------+-----------+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"DESCRIBE TABLE local.db.orders\").show(truncate=False)\n",
    "spark.sql(\"SELECT * FROM local.db.orders\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
