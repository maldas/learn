{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98f09f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Partitioned Iceberg Table (SQL) if it does not exist\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.db.partitioned_table (\n",
    "  id INT,\n",
    "  category STRING,\n",
    "  value DOUBLE\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (category)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe7332da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|category|value|\n",
      "+---+--------+-----+\n",
      "|  3|       B| 55.5|\n",
      "|  4|       C| 77.0|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert new records into an existing Iceberg table\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "new_data = [Row(id=3, category=\"B\", value=55.5), Row(id=4, category=\"C\", value=77.0)]\n",
    "df_new = spark.createDataFrame(new_data)\n",
    "\n",
    "df_new.writeTo(\"local.db.partitioned_table\").append()\n",
    "spark.read.table(\"local.db.partitioned_table\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23dff33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|category|value|\n",
      "+---+--------+-----+\n",
      "| 10|       X|100.0|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overwrite entire Iceberg table content\n",
    "\n",
    "overwrite_df = spark.createDataFrame([(10, \"X\", 100.0)], [\"id\", \"category\", \"value\"])\n",
    "\n",
    "overwrite_df.write.mode(\"overwrite\").saveAsTable(\"local.db.partitioned_table\")\n",
    "\n",
    "# Verify updated content\n",
    "spark.read.table(\"local.db.partitioned_table\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58a8d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|category|value|\n",
      "+---+--------+-----+\n",
      "| 10|       X|200.0|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform MERGE INTO for UPSERT operations (requires Iceberg 0.12+)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO local.db.partitioned_table t\n",
    "USING (SELECT 10 AS id, 'X' AS category, 200.0 AS value) s\n",
    "ON t.id = s.id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "spark.read.table(\"local.db.partitioned_table\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e44b1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|category|value|\n",
      "+---+--------+-----+\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete records using condition\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DELETE FROM local.db.partitioned_table\n",
    "WHERE category = 'X'\n",
    "\"\"\")\n",
    "\n",
    "spark.read.table(\"local.db.partitioned_table\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
